{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SurvSHAP(t): Time-Dependent Explanations Of Machine Learning Survival Models\n",
    "### M. Krzyziński, M. Spytek, H. Baniecki, P. Biecek\n",
    "## Experiment 1: Evaluating explanations on synthetic data\n",
    "### DATASET: `EXP1_complex`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import pickle\n",
    "import itertools\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing data and models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/home/jkrajewski/survshap/data/exp1_data_complex.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.util import Surv\n",
    "X = data.iloc[:, :5]\n",
    "y = Surv.from_dataframe(\"event\", \"time\", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6727416798732171"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
    "cph = CoxPHSurvivalAnalysis()\n",
    "cph.fit(X, y)\n",
    "cph.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7989963021658743"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "rsf = RandomSurvivalForest(random_state=42, n_estimators=100, min_samples_split=8, min_samples_leaf=4, max_features=3, max_samples=0.8)\n",
    "rsf.fit(X, y)\n",
    "rsf.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from survshap import SurvivalModelExplainer, PredictSurvSHAP, ModelSurvSHAP\n",
    "rsf_exp = SurvivalModelExplainer(rsf, X, y)\n",
    "cph_exp = SurvivalModelExplainer(cph, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:45<00:00,  2.22it/s]\n"
     ]
    }
   ],
   "source": [
    "exp1_survshap_global_rsf = ModelSurvSHAP(random_state=42)\n",
    "exp1_survshap_global_rsf.fit(rsf_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open(\"pickles/exp1_complex_survshap_global_rsf\", \"wb\") as file:\n",
    "#     pickle.dump(exp1_survshap_global_rsf, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:28<00:00,  3.53it/s]\n"
     ]
    }
   ],
   "source": [
    "exp1_survshap_global_cph = ModelSurvSHAP(random_state=42)\n",
    "exp1_survshap_global_cph.fit(cph_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"pickles/exp1_complex_survshap_global_cph\", \"wb\") as file:\n",
    "#     pickle.dump(exp1_survshap_global_cph, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating ground-truth SurvSHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.metrics import r2_score\n",
    "def shap_kernel(\n",
    "    explainer, new_observation, function_type, timestamps, baseline_f, simplified_inputs, kernel_weights, n\n",
    "):\n",
    "    data = generate_data(n)\n",
    "\n",
    "    shap_values, r2 = calculate_shap_values(\n",
    "        explainer.model,\n",
    "        function_type,\n",
    "        baseline_f,\n",
    "        data,\n",
    "        simplified_inputs,\n",
    "        kernel_weights,\n",
    "        new_observation,\n",
    "        timestamps,\n",
    "    )\n",
    "    result_shap = pd.DataFrame(\n",
    "        shap_values, columns=[\" = \".join([\"t\", str(time)]) for time in timestamps]\n",
    "    )\n",
    "\n",
    "    return result_shap, r2\n",
    "\n",
    "\n",
    "def generate_shap_kernel_weights(simplified_inputs, num_variables):\n",
    "    weights = []\n",
    "    for coalition_vector in simplified_inputs:\n",
    "        num_available_variables = np.count_nonzero(coalition_vector)\n",
    "        if num_available_variables == 0 or num_available_variables == num_variables:\n",
    "            weights.append(1e9)\n",
    "        else:\n",
    "            weights.append(\n",
    "                (num_variables - 1)\n",
    "                / (\n",
    "                    math.comb(num_variables, num_available_variables)\n",
    "                    * num_available_variables\n",
    "                    * (num_variables - num_available_variables)\n",
    "                )\n",
    "            )\n",
    "    return weights\n",
    "\n",
    "\n",
    "def make_prediction_for_simplified_input(\n",
    "    model, function_type, data, simplified_inputs, new_observation, timestamps\n",
    "):\n",
    "    preds = np.zeros((len(simplified_inputs), len(timestamps)))\n",
    "    for i, mask in enumerate(simplified_inputs):\n",
    "        X_tmp = pd.DataFrame(\n",
    "            np.where(mask, new_observation, data), columns=data.columns\n",
    "        )\n",
    "        preds[\n",
    "            i,\n",
    "        ] = calculate_mean_function(model, function_type, X_tmp, timestamps)\n",
    "    return preds\n",
    "\n",
    "def calculate_mean_function(model, function_type, data, timestamps):\n",
    "    if function_type == \"sf\":\n",
    "        all_functions = model.predict_survival_function(data)\n",
    "    elif function_type == \"chf\":\n",
    "        all_functions = model.predict_cumulative_hazard_function(data)\n",
    "    all_function_vals = [f(timestamps) for f in all_functions]\n",
    "    return np.mean(all_function_vals, axis=0)\n",
    "\n",
    "\n",
    "def calculate_shap_values(\n",
    "    model,\n",
    "    function_type,\n",
    "    avg_function,\n",
    "    data,\n",
    "    simplified_inputs,\n",
    "    shap_kernel_weights,\n",
    "    new_observation,\n",
    "    timestamps,\n",
    "):\n",
    "    W = np.diag(shap_kernel_weights)\n",
    "    X = np.array(simplified_inputs)\n",
    "    R = np.linalg.inv(X.T @ W @ X) @ (X.T @ W)\n",
    "    y = (\n",
    "        make_prediction_for_simplified_input(\n",
    "            model, function_type, data, simplified_inputs, new_observation, timestamps\n",
    "        )\n",
    "        - avg_function\n",
    "    )\n",
    "    shap_values = R @ y\n",
    "    y_pred = X @ shap_values\n",
    "    r2 = [None] * y.shape[1]\n",
    "    for i in range(y.shape[1]):\n",
    "        r2[i] = r2_score(y[:, i], y_pred[:, i], sample_weight=shap_kernel_weights)\n",
    "    return shap_values, r2\n",
    "\n",
    "def generate_data(n):\n",
    "    x1 = np.random.binomial(1, 0.5, n)\n",
    "    x2 = np.random.binomial(1, 0.5, n)\n",
    "    x3 = np.random.normal(10, 2, n)\n",
    "    x4 = np.random.normal(20, 4, n)\n",
    "    x5 = np.random.normal(0, 1, n)\n",
    "    return  pd.DataFrame({\"x1\": x1, \"x2\": x2, \"x3\": x3, \"x4\": x4, \"x5\": x5})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_functions_rsf = rsf.predict_survival_function(X)\n",
    "all_functions_vals = [f.y for f in all_functions_rsf]\n",
    "timestamps = all_functions_rsf[0].x\n",
    "baseline_f = np.mean(all_functions_vals, axis=0)\n",
    "simplified_inputs = [list(z) for z in itertools.product(range(2), repeat=5)]\n",
    "kernel_weights = generate_shap_kernel_weights(simplified_inputs, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42, stratify=y[\"event\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "positional indexers are out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/survshap/venv/lib/python3.8/site-packages/pandas/core/indexing.py:1587\u001b[0m, in \u001b[0;36m_iLocIndexer._get_list_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1586\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1587\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobj\u001b[39m.\u001b[39;49m_take_with_is_copy(key, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[1;32m   1588\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mIndexError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m   1589\u001b[0m     \u001b[39m# re-raise with different error message\u001b[39;00m\n",
      "File \u001b[0;32m~/survshap/venv/lib/python3.8/site-packages/pandas/core/generic.py:3902\u001b[0m, in \u001b[0;36mNDFrame._take_with_is_copy\u001b[0;34m(self, indices, axis)\u001b[0m\n\u001b[1;32m   3895\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   3896\u001b[0m \u001b[39mInternal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[1;32m   3897\u001b[0m \u001b[39mattribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3900\u001b[0m \u001b[39mSee the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[1;32m   3901\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m-> 3902\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_take(indices\u001b[39m=\u001b[39;49mindices, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[1;32m   3903\u001b[0m \u001b[39m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n",
      "File \u001b[0;32m~/survshap/venv/lib/python3.8/site-packages/pandas/core/generic.py:3886\u001b[0m, in \u001b[0;36mNDFrame._take\u001b[0;34m(self, indices, axis, convert_indices)\u001b[0m\n\u001b[1;32m   3884\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_consolidate_inplace()\n\u001b[0;32m-> 3886\u001b[0m new_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mtake(\n\u001b[1;32m   3887\u001b[0m     indices,\n\u001b[1;32m   3888\u001b[0m     axis\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_block_manager_axis(axis),\n\u001b[1;32m   3889\u001b[0m     verify\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   3890\u001b[0m     convert_indices\u001b[39m=\u001b[39;49mconvert_indices,\n\u001b[1;32m   3891\u001b[0m )\n\u001b[1;32m   3892\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor(new_data)\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtake\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/survshap/venv/lib/python3.8/site-packages/pandas/core/internals/managers.py:977\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[0;34m(self, indexer, axis, verify, convert_indices)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[39mif\u001b[39;00m convert_indices:\n\u001b[0;32m--> 977\u001b[0m     indexer \u001b[39m=\u001b[39m maybe_convert_indices(indexer, n, verify\u001b[39m=\u001b[39;49mverify)\n\u001b[1;32m    979\u001b[0m new_labels \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes[axis]\u001b[39m.\u001b[39mtake(indexer)\n",
      "File \u001b[0;32m~/survshap/venv/lib/python3.8/site-packages/pandas/core/indexers/utils.py:286\u001b[0m, in \u001b[0;36mmaybe_convert_indices\u001b[0;34m(indices, n, verify)\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[0;32m--> 286\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mindices are out-of-bounds\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    287\u001b[0m \u001b[39mreturn\u001b[39;00m indices\n",
      "\u001b[0;31mIndexError\u001b[0m: indices are out-of-bounds",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m to_calculate \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(X_test\u001b[39m.\u001b[39mindex)\n\u001b[1;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tqdm(to_calculate):\n\u001b[1;32m      4\u001b[0m     shap_gt \u001b[39m=\u001b[39m shap_kernel(\n\u001b[0;32m----> 5\u001b[0m         rsf_exp, X\u001b[39m.\u001b[39;49miloc[[i]], \u001b[39m\"\u001b[39m\u001b[39msf\u001b[39m\u001b[39m\"\u001b[39m, timestamps, baseline_f, simplified_inputs, kernel_weights, \u001b[39m10000\u001b[39m\n\u001b[1;32m      6\u001b[0m     )\n\u001b[1;32m      7\u001b[0m     shap_gt[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39minsert(\u001b[39m0\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m, i)\n\u001b[1;32m      8\u001b[0m     shap_groundtruth \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([shap_groundtruth, shap_gt[\u001b[39m0\u001b[39m]])\n",
      "File \u001b[0;32m~/survshap/venv/lib/python3.8/site-packages/pandas/core/indexing.py:1073\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1070\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[1;32m   1072\u001b[0m maybe_callable \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mapply_if_callable(key, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj)\n\u001b[0;32m-> 1073\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_axis(maybe_callable, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[0;32m~/survshap/venv/lib/python3.8/site-packages/pandas/core/indexing.py:1616\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1614\u001b[0m \u001b[39m# a list of integers\u001b[39;00m\n\u001b[1;32m   1615\u001b[0m \u001b[39melif\u001b[39;00m is_list_like_indexer(key):\n\u001b[0;32m-> 1616\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_list_axis(key, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[1;32m   1618\u001b[0m \u001b[39m# a single integer\u001b[39;00m\n\u001b[1;32m   1619\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1620\u001b[0m     key \u001b[39m=\u001b[39m item_from_zerodim(key)\n",
      "File \u001b[0;32m~/survshap/venv/lib/python3.8/site-packages/pandas/core/indexing.py:1590\u001b[0m, in \u001b[0;36m_iLocIndexer._get_list_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1587\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_take_with_is_copy(key, axis\u001b[39m=\u001b[39maxis)\n\u001b[1;32m   1588\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mIndexError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m   1589\u001b[0m     \u001b[39m# re-raise with different error message\u001b[39;00m\n\u001b[0;32m-> 1590\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mpositional indexers are out-of-bounds\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: positional indexers are out-of-bounds"
     ]
    }
   ],
   "source": [
    "shap_groundtruth = pd.DataFrame()\n",
    "to_calculate = list(X_test.index)\n",
    "for i in tqdm(to_calculate):\n",
    "    shap_gt = shap_kernel(\n",
    "        rsf_exp, X.iloc[[i]], \"sf\", timestamps, baseline_f, simplified_inputs, kernel_weights, 10000\n",
    "    )\n",
    "    shap_gt[0].insert(0, \"index\", i)\n",
    "    shap_groundtruth = pd.concat([shap_groundtruth, shap_gt[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_groundtruth.to_csv(\"results/exp1_shap_groundtruth_rsf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "all_functions_cph = cph.predict_survival_function(X)\n",
    "all_functions_vals = [f.y for f in all_functions_cph]\n",
    "timestamps = all_functions_cph[0].x\n",
    "baseline_f = np.mean(all_functions_vals, axis=0)\n",
    "simplified_inputs = [list(z) for z in itertools.product(range(2), repeat=5)]\n",
    "kernel_weights = generate_shap_kernel_weights(simplified_inputs, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_groundtruth_cph = pd.DataFrame()\n",
    "to_calculate = list(X_test.index)\n",
    "for i in tqdm(to_calculate):\n",
    "    shap_gt = shap_kernel(\n",
    "        cph_exp, X.iloc[[i]], \"sf\", timestamps, baseline_f, simplified_inputs, kernel_weights, 10000\n",
    "    )\n",
    "    shap_gt[0].insert(0, \"index\", i)\n",
    "    shap_groundtruth_cph = pd.concat([shap_groundtruth_cph, shap_gt[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_groundtruth_cph.to_csv(\"results/exp1_shap_groundtruth_cph.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_grountruth_rsf = pd.read_csv(\"results/exp1_shap_groundtruth_rsf.csv\")\n",
    "shap_grountruth_cph = pd.read_csv(\"results/exp1_shap_groundtruth_cph.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pickles/exp1_complex_survshap_global_rsf\", \"rb\") as file:\n",
    "    exp1_survshap_global_rsf = pickle.load(file)\n",
    "with open(\"pickles/exp1_complex_survshap_global_cph\", \"rb\") as file:\n",
    "    exp1_survshap_global_cph = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SurvSHAP(t) values plot example\n",
    "\n",
    "example_rsf = deepcopy(exp1_survshap_global_rsf.individual_explanations[690])\n",
    "example_cph = deepcopy(exp1_survshap_global_cph.individual_explanations[690])\n",
    "\n",
    "melted_example_rsf = pd.melt(example_rsf.result, id_vars=\"variable_name\", value_vars=example_rsf.result.columns[6:])\n",
    "melted_example_rsf[\"variable\"] = melted_example_rsf[\"variable\"].str[4:].astype(float)\n",
    "melted_example_rsf.to_csv(\"results/exp1_example_rsf.csv\", index=False)\n",
    "melted_example_cph = pd.melt(example_cph.result, id_vars=\"variable_name\", value_vars=example_cph.result.columns[6:])\n",
    "melted_example_cph[\"variable\"] = melted_example_cph[\"variable\"].str[4:].astype(float)\n",
    "melted_example_cph.to_csv(\"results/exp1_example_cph.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalized SurvSHAP(t) values plot example\n",
    "\n",
    "example_rsf.result.iloc[:, 5:] = np.nan_to_num(\n",
    "            example_rsf.result[example_rsf.result[\"B\"] == 0].iloc[:, 5:]\n",
    "            / example_rsf.result[example_rsf.result[\"B\"] == 0].iloc[:, 5:].abs().sum())\n",
    "\n",
    "example_cph.result.iloc[:, 5:] = np.nan_to_num(\n",
    "            example_cph.result[example_cph.result[\"B\"] == 0].iloc[:, 5:]\n",
    "            / example_cph.result[example_cph.result[\"B\"] == 0].iloc[:, 5:].abs().sum())\n",
    "\n",
    "melted_example_norm_rsf = pd.melt(example_rsf.result, id_vars=\"variable_name\", value_vars=example_rsf.result.columns[6:])\n",
    "melted_example_norm_rsf[\"variable\"] = melted_example_norm_rsf[\"variable\"].str[4:].astype(float)\n",
    "melted_example_norm_rsf.to_csv(\"results/exp1_example_norm_rsf.csv\", index=False)\n",
    "\n",
    "melted_example_norm_cph = pd.melt(example_cph.result, id_vars=\"variable_name\", value_vars=example_cph.result.columns[6:])\n",
    "melted_example_norm_cph[\"variable\"] = melted_example_norm_cph[\"variable\"].str[4:].astype(float)\n",
    "melted_example_norm_cph.to_csv(\"results/exp1_example_norm_cph.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Changing Signs Proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_signs_rsf = np.sign(exp1_survshap_global_rsf.full_result.iloc[:, 6:].values)\n",
    "timestamps_rsf = exp1_survshap_global_rsf.timestamps\n",
    "\n",
    "shap_signs_cph = np.sign(exp1_survshap_global_cph.full_result.iloc[:, 6:].values)\n",
    "timestamps_cph = exp1_survshap_global_cph.timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_index, end_index = np.where((timestamps_rsf >= np.percentile(timestamps_rsf, 10)) & (timestamps_rsf <= np.percentile(timestamps_rsf, 90)))[0][[0, -1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_ranges = []\n",
    "for row in shap_signs_rsf:\n",
    "    sign_ranges_row = []\n",
    "    last_sign = row[start_index]\n",
    "    start_time_sign_sequence = timestamps_rsf[start_index]\n",
    "    for i in range(start_index, end_index+1):\n",
    "        if row[i] != last_sign and row[i] != 0:\n",
    "            sign_ranges_row.append(last_sign*(timestamps_rsf[i-1] - start_time_sign_sequence))\n",
    "            start_time_sign_sequence = timestamps_rsf[i-1]\n",
    "        if row[i] != 0:\n",
    "            last_sign = row[i] \n",
    "    sign_ranges_row.append(last_sign*(timestamps_rsf[i] - start_time_sign_sequence))\n",
    "    sign_ranges.append(sign_ranges_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_range = [sum(sign_seq_range for sign_seq_range in sign_ranges_row if sign_seq_range < 0) for sign_ranges_row in sign_ranges]\n",
    "positive_range = [sum(sign_seq_range for sign_seq_range in sign_ranges_row if sign_seq_range > 0) for sign_ranges_row in sign_ranges]\n",
    "timestamps_range = timestamps_rsf[end_index] - timestamps_rsf[start_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changed_signs_005 = (np.abs(np.array(negative_range)) >= 0.05 * timestamps_range) & (np.array(positive_range) >= 0.05 * timestamps_range)\n",
    "changed_signs_01 = (np.abs(np.array(negative_range)) >= 0.1 * timestamps_range) & (np.array(positive_range) >= 0.1 * timestamps_range)\n",
    "changed_signs_02 = (np.abs(np.array(negative_range)) >= 0.2 * timestamps_range) & (np.array(positive_range) >= 0.2 * timestamps_range)\n",
    "csp_rsf = pd.DataFrame({\"variable_name\": exp1_survshap_global_rsf.full_result.variable_name, \n",
    "                                \"variable_value\": exp1_survshap_global_rsf.full_result.variable_value, \n",
    "                                \"index\": exp1_survshap_global_rsf.full_result.index, \n",
    "                                \"changed_signs_0.05\": changed_signs_005,\n",
    "                                \"changed_signs_0.1\": changed_signs_01,\n",
    "                                \"changed_signs_0.2\": changed_signs_02})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_index, end_index = np.where((timestamps_cph >= np.percentile(timestamps_rsf, 10)) & (timestamps_cph <= np.percentile(timestamps_rsf, 90)))[0][[0, -1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_ranges = []\n",
    "for row in shap_signs_cph:\n",
    "    sign_ranges_row = []\n",
    "    last_sign = row[start_index]\n",
    "    start_time_sign_sequence = timestamps_cph[start_index]\n",
    "    for i in range(start_index, end_index):\n",
    "        if row[i] != last_sign and row[i] != 0:\n",
    "            sign_ranges_row.append(last_sign*(timestamps_cph[i-1] - start_time_sign_sequence))\n",
    "            start_time_sign_sequence = timestamps_cph[i-1]\n",
    "        if row[i] != 0:\n",
    "            last_sign = row[i] \n",
    "    sign_ranges_row.append(last_sign*(timestamps_cph[i] - start_time_sign_sequence))\n",
    "    sign_ranges.append(sign_ranges_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_range = [sum(sign_seq_range for sign_seq_range in sign_ranges_row if sign_seq_range < 0) for sign_ranges_row in sign_ranges]\n",
    "positive_range = [sum(sign_seq_range for sign_seq_range in sign_ranges_row if sign_seq_range > 0) for sign_ranges_row in sign_ranges]\n",
    "timestamps_range = timestamps_cph[-1] - timestamps_cph[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changed_signs_005 = (np.abs(np.array(negative_range)) >= 0.05 * timestamps_range) & (np.array(positive_range) >= 0.05 * timestamps_range)\n",
    "changed_signs_01 = (np.abs(np.array(negative_range)) >= 0.1 * timestamps_range) & (np.array(positive_range) >= 0.1 * timestamps_range)\n",
    "changed_signs_02 = (np.abs(np.array(negative_range)) >= 0.2 * timestamps_range) & (np.array(positive_range) >= 0.2 * timestamps_range)\n",
    "csp_cph = pd.DataFrame({\"variable_name\": exp1_survshap_global_cph.full_result.variable_name, \n",
    "                                \"variable_value\": exp1_survshap_global_cph.full_result.variable_value, \n",
    "                                \"index\": exp1_survshap_global_cph.full_result.index, \n",
    "                                \"changed_signs_0.05\": changed_signs_005,\n",
    "                                \"changed_signs_0.1\": changed_signs_01,\n",
    "                                \"changed_signs_0.2\": changed_signs_02})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csp_rsf.groupby(\"variable_name\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csp_cph.groupby(\"variable_name\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Local accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_local_accuracy_from_shap_explanations(all_explanation, label, last_index=None):\n",
    "    if last_index is None:\n",
    "        last_index=len(all_explanation.timestamps)\n",
    "    diffs = []\n",
    "    preds = []\n",
    "    for explanation in all_explanation.individual_explanations:\n",
    "        preds.append(explanation.predicted_function[:last_index])\n",
    "        diffs.append(explanation.predicted_function[:last_index] - explanation.baseline_function[:last_index] - np.array(explanation.result.iloc[:, 6:].sum(axis=0))[:last_index])\n",
    "    diffs_squared = np.array(diffs)**2\n",
    "    E_diffs_sqared = np.mean(diffs_squared, axis=0)\n",
    "    preds_squared = np.array(preds)**2\n",
    "    E_preds_squared = np.mean(preds_squared, axis=0)\n",
    "    return  pd.DataFrame({\"time\": all_explanation.timestamps[:last_index], \"sigma\": np.sqrt(E_diffs_sqared) / np.sqrt(E_preds_squared), \"label\": label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_accuracy_rsf = get_local_accuracy_from_shap_explanations(exp1_survshap_global_rsf, \"RSF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_accuracy_cph = get_local_accuracy_from_shap_explanations(exp1_survshap_global_cph, \"CPH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([local_accuracy_rsf, local_accuracy_cph]).to_csv(\"results/exp1_local_accuracy.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GT-Shapley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_grountruth_rsf = shap_grountruth_rsf.sort_values(by=[\"observation_index\", \"variable_index\"]) \n",
    "shap_grountruth_cph = shap_grountruth_cph.sort_values(by=[\"observation_index\", \"variable_index\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_rsf = shap_grountruth_rsf.values[:, 2:] - exp1_survshap_global_rsf.full_result[exp1_survshap_global_rsf.full_result[\"index\"].isin(shap_grountruth_rsf[\"observation_index\"])].values[:, 6:]\n",
    "diff_cph = shap_grountruth_cph.values[:, 2:] - exp1_survshap_global_cph.full_result[exp1_survshap_global_cph.full_result[\"index\"].isin(shap_grountruth_cph[\"observation_index\"])].values[:, 6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_shap_profiles_rsf = shap_grountruth_rsf.values[:, 2:]\n",
    "gt_shap_profiles_cph = shap_grountruth_cph.values[:, 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_rsf = np.sqrt(np.array(np.mean(diff_rsf**2, axis=0), dtype=np.float64))\n",
    "rmse_gt_shap_profiles_rsf = np.sqrt(np.array(np.mean(gt_shap_profiles_rsf**2, axis=0), dtype=np.float64))\n",
    "rmse_cph = np.sqrt(np.array(np.mean(diff_cph**2, axis=0), dtype=np.float64))\n",
    "rmse_gt_shap_profiles_cph = np.sqrt(np.array(np.mean(gt_shap_profiles_cph**2, axis=0), dtype=np.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_comp_by_vars_rsf = np.zeros((5, 669))\n",
    "for i in range(5): \n",
    "    rmse = np.sqrt(np.array(np.mean(diff_rsf[i::5,] **2, axis=0), dtype=np.float64)) \n",
    "    normalization_factor = np.sqrt(np.array(np.mean(gt_shap_profiles_rsf[i::5,]**2, axis=0), dtype=np.float64))\n",
    "    gt_comp_by_vars_rsf[i,:] = rmse/normalization_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_comp_by_vars_cph = np.zeros((5, 1000))\n",
    "for i in range(5): \n",
    "    rmse = np.sqrt(np.array(np.mean(diff_cph[i::5,] **2, axis=0), dtype=np.float64)) \n",
    "    normalization_factor = np.sqrt(np.array(np.mean(gt_shap_profiles_cph[i::5,]**2, axis=0), dtype=np.float64))\n",
    "    gt_comp_by_vars_cph[i,:] = rmse/normalization_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame(gt_comp_by_vars_rsf, index=[\"x1\", \"x2\", \"x3\", \"x4\", \"x5\"], columns=timestamps_rsf).reset_index().rename(columns={\"index\": \"variable_name\"})\n",
    "pd.melt(tmp, id_vars=\"variable_name\", value_vars=tmp.columns).to_csv(\"results/exp1_gt_shap_rsf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame(gt_comp_by_vars_cph, index=[\"x1\", \"x2\", \"x3\", \"x4\", \"x5\"], columns=timestamps_cph).reset_index().rename(columns={\"index\": \"variable_name\"})\n",
    "pd.melt(tmp, id_vars=\"variable_name\", value_vars=tmp.columns).to_csv(\"results/exp1_gt_shap_cph.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GT_Shapley(all_explanation, groundtruth, label):\n",
    "    corrs = []\n",
    "    for i in range(1, 100):\n",
    "        gt = (groundtruth.values[(i*5):(i*5+5), 2:])\n",
    "        obt = (np.array(all_explanation.full_result[all_explanation.full_result[\"index\"].isin(groundtruth[\"observation_index\"])].values[(i*5):(i*5+5), 6:], dtype=np.float64))\n",
    "        corrs.append(pd.DataFrame(gt).corrwith(pd.DataFrame(obt), axis=0))\n",
    "    return  pd.DataFrame({\"time\": all_explanation.timestamps, \"correlation\": np.array(corrs).mean(axis=0), \"label\": label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([GT_Shapley(exp1_survshap_global_rsf, shap_grountruth_rsf, \"RSF\"), GT_Shapley(exp1_survshap_global_cph, shap_grountruth_cph, \"CPH\")]).to_csv(\"results/exp1_corr.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "862e00d4e923d07bafe3efd192af1b4097c7ce8d60181494a0e8b306ca1d81fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
